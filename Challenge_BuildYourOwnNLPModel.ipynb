{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language processing\n",
    "# Challenge: Build your own NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning for BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw Moby Dick:\n",
      " [Moby Dick by Herman Melville 1851]\r\n",
      "\r\n",
      "\r\n",
      "ETYMOLOGY.\r\n",
      "\r\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\r\n",
      "\r\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\r\n",
      "now.  He was ever dusting his old lexicons and grammars, with a queer\r\n",
      "handkerchief, mockingly embellished with all the gay flags of all the\r\n",
      "known nations of the world.  He loved to dust his old grammars; it\r\n",
      "somehow mildly reminded him of his mortality.\r\n",
      "\r\n",
      "\"While you take in hand to school others, and to teac\n",
      "\n",
      "Raw Paradise:\n",
      " [Paradise Lost by John Milton 1667] \n",
      " \n",
      " \n",
      "Book I \n",
      " \n",
      " \n",
      "Of Man's first disobedience, and the fruit \n",
      "Of that forbidden tree whose mortal taste \n",
      "Brought death into the World, and all our woe, \n",
      "With loss of Eden, till one greater Man \n",
      "Restore us, and regain the blissful seat, \n",
      "Sing, Heavenly Muse, that, on the secret top \n",
      "Of Oreb, or of Sinai, didst inspire \n",
      "That shepherd who first taught the chosen seed \n",
      "In the beginning how the heavens and earth \n",
      "Rose out of Chaos: or, if Sion hill \n",
      "Delight thee mor\n"
     ]
    }
   ],
   "source": [
    "moby = gutenberg.raw('melville-moby_dick.txt')\n",
    "paradise = gutenberg.raw('milton-paradise.txt')\n",
    "\n",
    "# Print the first 500 characters of Moby Dick.\n",
    "print('\\nRaw Moby Dick:\\n', moby[0:500])\n",
    "\n",
    "# Print the first 500 characters of Paradise\n",
    "print('\\nRaw Paradise:\\n', paradise[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter headings removed Moby Dick:\n",
      " \r\n",
      "\r\n",
      "\r\n",
      "ETYMOLOGY.\r\n",
      "\r\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\r\n",
      "\r\n",
      "The pale Usher--th\n",
      "\n",
      "Chapter headings removed Paradise:\n",
      "  \n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \n",
      "Of Man's first disobedience, and the fruit \n",
      "Of that forbidden tree whose mortal taste \n",
      "Br\n"
     ]
    }
   ],
   "source": [
    "# This pattern matches all text between square brackets.\n",
    "pattern = \"[\\[].*?[\\]]\"\n",
    "moby = re.sub(pattern, \"\", moby)\n",
    "paradise = re.sub(pattern, \"\", paradise)\n",
    "\n",
    "# Now we'll match and remove chapter headings.\n",
    "# The Chapter indicator is idiosyncratic\n",
    "moby = re.sub(r'Chapter \\d+', '', moby)\n",
    "paradise = re.sub(r'Book .*', '', paradise)\n",
    "    \n",
    "# Ok, what's it look like now?\n",
    "print('Chapter headings removed Moby Dick:\\n', moby[0:100])\n",
    "\n",
    "print('\\nChapter headings removed Paradise:\\n', paradise[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features Using BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moby = text_cleaner(moby)\n",
    "paradise = text_cleaner(paradise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "nlp.max_length = 2000000\n",
    "moby_doc = nlp(moby)\n",
    "paradise_doc = nlp(paradise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ETYMOLOGY, .)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((, Supplied, by, a, Late, Consumptive)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Usher, to, a, Grammar, School, ))</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(The, pale, Usher, threadbare, in, coat, ,, he...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(;, I, see, him, now, .)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0                                     (ETYMOLOGY, .)  Melville\n",
       "1            ((, Supplied, by, a, Late, Consumptive)  Melville\n",
       "2                 (Usher, to, a, Grammar, School, ))  Melville\n",
       "3  (The, pale, Usher, threadbare, in, coat, ,, he...  Melville\n",
       "4                           (;, I, see, him, now, .)  Melville"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "moby_sents = [[sent, \"Melville\"] for sent in moby_doc.sents]\n",
    "paradise_sents = [[sent, \"Milton\"] for sent in paradise_doc.sents]\n",
    "\n",
    "#Moby Dick is quite long, let's cut it down to the same length as Paradise.\n",
    "moby_sents = moby_sents[0:len(paradise_sents)]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(moby_sents + paradise_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "mobywords = bag_of_words(moby_doc)\n",
    "paradisewords = bag_of_words(paradise_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(mobywords + paradisewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fame</th>\n",
       "      <th>restraint</th>\n",
       "      <th>cheek</th>\n",
       "      <th>speech</th>\n",
       "      <th>critical</th>\n",
       "      <th>lima</th>\n",
       "      <th>ill</th>\n",
       "      <th>mood</th>\n",
       "      <th>invariably</th>\n",
       "      <th>allude</th>\n",
       "      <th>...</th>\n",
       "      <th>dumb</th>\n",
       "      <th>dalliance</th>\n",
       "      <th>stroke</th>\n",
       "      <th>stir</th>\n",
       "      <th>desire</th>\n",
       "      <th>end</th>\n",
       "      <th>length</th>\n",
       "      <th>win</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ETYMOLOGY, .)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>((, Supplied, by, a, Late, Consumptive)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Usher, to, a, Grammar, School, ))</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, pale, Usher, threadbare, in, coat, ,, he...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(;, I, see, him, now, .)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3021 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fame restraint cheek speech critical lima ill mood invariably allude  \\\n",
       "0    0         0     0      0        0    0   0    0          0      0   \n",
       "1    0         0     0      0        0    0   0    0          0      0   \n",
       "2    0         0     0      0        0    0   0    0          0      0   \n",
       "3    0         0     0      0        0    0   0    0          0      0   \n",
       "4    0         0     0      0        0    0   0    0          0      0   \n",
       "\n",
       "      ...     dumb dalliance stroke stir desire end length win  \\\n",
       "0     ...        0         0      0    0      0   0      0   0   \n",
       "1     ...        0         0      0    0      0   0      0   0   \n",
       "2     ...        0         0      0    0      0   0      0   0   \n",
       "3     ...        0         0      0    0      0   0      0   0   \n",
       "4     ...        0         0      0    0      0   0      0   0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0                                     (ETYMOLOGY, .)    Melville  \n",
       "1            ((, Supplied, by, a, Late, Consumptive)    Melville  \n",
       "2                 (Usher, to, a, Grammar, School, ))    Melville  \n",
       "3  (The, pale, Usher, threadbare, in, coat, ,, he...    Melville  \n",
       "4                           (;, I, see, him, now, .)    Melville  \n",
       "\n",
       "[5 rows x 3021 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Test Sets \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Set variables.\n",
    "Y_bow = word_counts['text_source']\n",
    "X_bow = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "# Train, test split.\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow,\n",
    "                                                                    Y_bow, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    random_state= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Using Bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.888198757764\n",
      "\n",
      "Test set score: 0.838768115942\n",
      "\n",
      "Cross validation results: 85.507% ± 1.690% \n",
      " \n",
      " [ 0.84864166  0.84217335  0.86287193  0.86416559  0.85751295]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "rfc = ensemble.RandomForestClassifier(max_depth=20,max_features='auto', n_estimators=100)\n",
    "rfc.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_bow, y_train_bow))\n",
    "print('\\nTest set score:', rfc.score(X_test_bow, y_test_bow))\n",
    "\n",
    "cv_train = cross_val_score(rfc, X_train_bow, y_train_bow, cv=5)\n",
    "\n",
    "### Put this with the Cros validation score.\n",
    "plusminus = u\"\\u00B1\"\n",
    " \n",
    "print('\\nCross validation results: {:.3%} {} {:.3%} \\n \\n {}'.format(cv_train.mean(), plusminus, 2*cv_train.std(), cv_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is overfitting but fitting well on the Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression : Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.937370600414\n",
      "\n",
      "Test set score: 0.878019323671\n",
      "\n",
      "Cross validation results: 87.966% ± 1.403% \n",
      " \n",
      " [ 0.87063389  0.88486417  0.87839586  0.89003881  0.87435233]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ridgeregr = LogisticRegression(penalty='l1')\n",
    "ridgeregr.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print('Training set score:', ridgeregr.score(X_train_bow, y_train_bow))\n",
    "print('\\nTest set score:', ridgeregr.score(X_test_bow, y_test_bow))\n",
    "\n",
    "cv_train = cross_val_score(ridgeregr, X_train_bow, y_train_bow, cv=5)\n",
    "\n",
    "### Put this with the Cros validation score.\n",
    "plusminus = u\"\\u00B1\"\n",
    " \n",
    "print('\\nCross validation results: {:.3%} {} {:.3%} \\n \\n {}'.format(cv_train.mean(), plusminus, 2*cv_train.std(), cv_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is overfitting but fitting well on the training set.   \n",
    "The standard deviation is high compare to the random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning for tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moby Dick:\n",
      " ['[ Moby Dick by Herman Melville 1851 ]', 'ETYMOLOGY .', '( Supplied by a Late Consumptive Usher to a Grammar School )', 'The pale Usher  threadbare in coat , heart , body , and brain ; I see him now .']\n",
      "\n",
      "Paradise:\n",
      " ['[ Paradise Lost by John Milton 1667 ]', 'Book I', \"Of Man ' s first disobedience , and the fruit Of that forbidden tree whose mortal taste Brought death into the World , and all our woe , With loss of Eden , till one greater Man Restore us , and regain the blissful seat , Sing , Heavenly Muse , that , on the secret top Of Oreb , or of Sinai , didst inspire That shepherd who first taught the chosen seed In the beginning how the heavens and earth Rose out of Chaos : or , if Sion hill Delight thee more , and Siloa ' s brook that flowed Fast by the oracle of God , I thence Invoke thy aid to my adventurous song , That with no middle flight intends to soar Above th ' Aonian mount , while it pursues Things unattempted yet in prose or rhyme .\", 'Book II']\n"
     ]
    }
   ],
   "source": [
    "#reading in the data, this time in the form of paragraphs\n",
    "moby_p =gutenberg.paras('melville-moby_dick.txt')\n",
    "#processing\n",
    "moby_paras=[]\n",
    "for paragraph in moby_p:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    moby_paras.append(' '.join(para))\n",
    "\n",
    "print('\\nMoby Dick:\\n',moby_paras[0:4])\n",
    "\n",
    "\n",
    "paradise_p =gutenberg.paras('milton-paradise.txt')\n",
    "#processing\n",
    "paradise_paras=[]\n",
    "for paragraph in paradise_p:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    paradise_paras.append(' '.join(para))\n",
    "\n",
    "print('\\nParadise:\\n',paradise_paras[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Moby Dick by Herman Melville 1851 ]</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETYMOLOGY .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>( Supplied by a Late Consumptive Usher to a Gr...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The pale Usher  threadbare in coat , heart , b...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" While you take in hand to school others , an...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0              [ Moby Dick by Herman Melville 1851 ]  Melville\n",
       "1                                        ETYMOLOGY .  Melville\n",
       "2  ( Supplied by a Late Consumptive Usher to a Gr...  Melville\n",
       "3  The pale Usher  threadbare in coat , heart , b...  Melville\n",
       "4  \" While you take in hand to school others , an...  Melville"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "moby_sents_tfidf = [[sent, \"Melville\"] for sent in moby_paras]\n",
    "paradise_sents_tfidf = [[sent, \"Milton\"] for sent in paradise_paras]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences_tfidf = pd.DataFrame(moby_sents_tfidf + paradise_sents_tfidf)\n",
    "sentences_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and Test Sets \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(sentences_tfidf[0],\n",
    "                                                                            sentences_tfidf[1], \n",
    "                                                                            test_size=0.4, \n",
    "                                                                            random_state=None)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "X_train_tfidf=vectorizer.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf=vectorizer.transform(X_test_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Using tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.995274660366\n",
      "\n",
      "Test set score: 0.990256864482\n",
      "\n",
      "Cross validation results: 99.055% ± 0.444% \n",
      " \n",
      " [ 0.99115044  0.99410029  0.99115044  0.98816568  0.98816568]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', rfc.score(X_test_tfidf, y_test_tfidf))\n",
    "\n",
    "cv_train = cross_val_score(rfc, X_train_tfidf, y_train_tfidf, cv=5)\n",
    "\n",
    "### Put this with the Cros validation score.\n",
    "plusminus = u\"\\u00B1\"\n",
    " \n",
    "print('\\nCross validation results: {:.3%} {} {:.3%} \\n \\n {}'.format(cv_train.mean(), plusminus, 2*cv_train.std(), cv_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression : Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.989367985824\n",
      "\n",
      "Test set score: 0.990256864482\n",
      "\n",
      "Cross validation results: 98.937% ± 0.286% \n",
      " \n",
      " [ 0.98820059  0.98820059  0.98820059  0.99112426  0.99112426]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ridgeregr = LogisticRegression()\n",
    "ridgeregr.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "print('Training set score:', ridgeregr.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', ridgeregr.score(X_test_tfidf, y_test_tfidf))\n",
    "\n",
    "\n",
    "cv_train = cross_val_score(ridgeregr, X_train_tfidf, y_train_tfidf, cv=5)\n",
    "\n",
    "### Put this with the Cros validation score.\n",
    "plusminus = u\"\\u00B1\"\n",
    " \n",
    "print('\\nCross validation results: {:.3%} {} {:.3%} \\n \\n {}'.format(cv_train.mean(), plusminus, 2*cv_train.std(), cv_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that using tf-idf in comparison to BoW is giving us the better results.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve on one of the model \n",
    "Pick one of the models and try to increase accuracy by at least 5 percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the work above, it looks like the Ridge Regression and Random Forest Classifier performs about the same  using features from __tf-idf__.  \n",
    "Using BoW, I will try to improve on what we have on the random Forest Classifier.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.930383022774\n",
      "\n",
      "Test set score: 0.852657004831\n",
      "\n",
      "Cross validation results: 86.258% ± 1.449% \n",
      " \n",
      " [ 0.85510996  0.85640362  0.85899094  0.86934023  0.87305699]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rfc = ensemble.RandomForestClassifier(max_depth=50,max_features='auto', n_estimators=200)\n",
    "rfc.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_bow, y_train_bow))\n",
    "print('\\nTest set score:', rfc.score(X_test_bow, y_test_bow))\n",
    "\n",
    "cv_train = cross_val_score(rfc, X_train_bow, y_train_bow, cv=5)\n",
    "\n",
    "### Put this with the Cros validation score.\n",
    "plusminus = u\"\\u00B1\"\n",
    " \n",
    "print('\\nCross validation results: {:.3%} {} {:.3%} \\n \\n {}'.format(cv_train.mean(), plusminus, 2*cv_train.std(), cv_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We were able to improve our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
